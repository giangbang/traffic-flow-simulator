[(array([[0.       , 0.0267037, 0.       , 0.       , 0.       , 0.       ,
        0.       , 0.       ]], dtype=float32), array([[0]], dtype=int64), array([[0.        , 0.03337962, 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        ]], dtype=float32), array([[0.]], dtype=float32)), (array([[0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32), array([[0]], dtype=int64), array([[0.        , 0.00667592, 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        ]], dtype=float32), array([[0.]], dtype=float32)), (array([[0.        , 0.03337962, 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        ]], dtype=float32), array([[0]], dtype=int64), array([[0.        , 0.04005554, 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        ]], dtype=float32), array([[0.]], dtype=float32)), (array([[0.        , 0.04005554, 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        ]], dtype=float32), array([[0]], dtype=int64), array([[0.        , 0.04321487, 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        ]], dtype=float32), array([[0.]], dtype=float32))]
state
tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0334, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0401, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0334, 0.0000, 0.0000]])
action
tensor([[0],
        [0],
        [0],
        [0]])
next_state
tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0401, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0432, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0067, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0401, 0.0000, 0.0000]])
reward
tensor([[0.],
        [0.],
        [0.],
        [0.]])
value
tensor([[ 0.0061, -0.3898, -0.0794],
        [ 0.0055, -0.3908, -0.0799],
        [ 0.0093, -0.3850, -0.0772],
        [ 0.0061, -0.3898, -0.0794]], grad_fn=<AddmmBackward>)
chosen action
tensor([[0.0061],
        [0.0055],
        [0.0093],
        [0.0061]], grad_fn=<GatherBackward>)
reward
{'0': array([[0.]], dtype=float32)}